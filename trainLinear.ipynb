{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anime Recommendation Training\n",
    "Train embeddings for users and anime using PyTorch, with genre features and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training parameters and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_RATINGS = 127_866_421\n",
    "BATCH_SIZE = 1024\n",
    "TOTAL_BATCHES = TOTAL_RATINGS // BATCH_SIZE\n",
    "CHECKPOINT_PATH = \"checkpoints/linear\"\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "CHECKPOINT_INTERVAL = 15_000\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load anime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_id_to_idx = torch.load(\"data/pt_files/anime_id_to_idx.pt\", weights_only=False)\n",
    "anime_genres = torch.load(\"data/pt_files/anime_genres.pt\")\n",
    "\n",
    "num_anime, num_genres = anime_genres.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Map all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_to_idx = torch.load(\"data/pt_files/user_id_to_idx.pt\")\n",
    "num_users = len(user_id_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsPTDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, pt_files):\n",
    "        super().__init__()\n",
    "        self.pt_files = pt_files\n",
    "\n",
    "    def __iter__(self):\n",
    "        for pt_file in self.pt_files:\n",
    "            data = torch.load(pt_file)\n",
    "            for u, a, s in zip(data[\"user_idx\"], data[\"anime_idx\"], data[\"scores\"]):\n",
    "                yield u, a, s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMF(nn.Module):\n",
    "    def __init__(self, num_users, num_anime, num_genres, \n",
    "                 user_dim=64, anime_dim=128, genre_proj_dim=16):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, user_dim)\n",
    "        self.anime_emb = nn.Embedding(num_anime, anime_dim)\n",
    "        self.W_genre = nn.Linear(num_genres, genre_proj_dim)\n",
    "        self.project = nn.Linear(anime_dim + genre_proj_dim, user_dim)\n",
    "\n",
    "    def forward(self, user_idx, anime_idx, anime_genres):\n",
    "        u = self.user_emb(user_idx)\n",
    "        v = self.anime_emb(anime_idx)\n",
    "        g = self.W_genre(anime_genres[anime_idx])\n",
    "        v_combined = torch.cat([v, g], dim=1)\n",
    "        v_proj = self.project(v_combined)\n",
    "        r_hat = (u * v_proj).sum(dim=1)\n",
    "        return r_hat\n",
    "    \n",
    "    def recommend(self, user_idx, anime_genres, top_k=10, device=\"cpu\", exclude_ids=None):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Repeat user_idx across all anime\n",
    "            user_tensor = torch.tensor([user_idx] * anime_genres.size(0), \n",
    "                                       dtype=torch.long, device=device)\n",
    "            anime_tensor = torch.arange(anime_genres.size(0), \n",
    "                                        dtype=torch.long, device=device)\n",
    "            \n",
    "            preds = self.forward(user_tensor, anime_tensor, anime_genres)\n",
    "            \n",
    "            if exclude_ids is not None:\n",
    "                preds[exclude_ids] = float(\"-inf\")  # mask out watched anime\n",
    "\n",
    "            # Get top-k indices\n",
    "            top_scores, top_indices = torch.topk(preds, top_k)\n",
    "        \n",
    "        return top_indices.cpu().tolist(), top_scores.cpu().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LinearMF(num_users, num_anime, num_genres).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, batch_in_epoch, loss, filename):\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"batch_in_epoch\": batch_in_epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": loss,\n",
    "    }, filename)\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename, device):\n",
    "    checkpoint = torch.load(filename, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    start_epoch = checkpoint.get(\"epoch\", 0)\n",
    "    start_batch_in_epoch = checkpoint.get(\"batch_in_epoch\", 0)\n",
    "    loss = checkpoint[\"loss\"]\n",
    "    return start_epoch, start_batch_in_epoch, loss\n",
    "\n",
    "# dataset = RatingsDataset(csv_files, user_id_to_idx, anime_id_to_idx)\n",
    "pt_files = sorted(glob.glob(\"data/pt_files/user_anime*_filtered.pt\"))\n",
    "dataset = RatingsPTDataset(pt_files)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "anime_genres = anime_genres.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851599e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from checkpoints\\epoch17.pth, epoch=16, batch_in_epoch=75000, prev_loss=2.7415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 90003/124869 [19:53<4:42:32,  2.06it/s, loss=2.68] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch17.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105002/124869 [29:21<1:15:39,  4.38it/s, loss=2.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch17.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120002/124869 [41:18<22:57,  3.53it/s, loss=2.68]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch17.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 124870it [44:23, 46.89it/s, loss=2.67]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch17.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20:  12%|‚ñà‚ñè        | 15003/124869 [09:52<10:10:25,  3.00it/s, loss=2.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20:  24%|‚ñà‚ñà‚ñç       | 30003/124869 [19:09<8:56:13,  2.95it/s, loss=2.68] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20:  36%|‚ñà‚ñà‚ñà‚ñå      | 45005/124869 [28:33<3:44:25,  5.93it/s, loss=2.63] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 60004/124869 [38:10<4:14:22,  4.25it/s, loss=2.61] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 74998/124869 [48:09<26:15, 31.66it/s, loss=2.6]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 89999/124869 [58:15<18:30, 31.41it/s, loss=2.59]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105004/124869 [1:08:35<1:32:42,  3.57it/s, loss=2.59] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120003/124869 [1:18:51<39:11,  2.07it/s, loss=2.59]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 124870it [1:21:52, 25.42it/s, loss=2.59]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20:  12%|‚ñà‚ñè        | 15003/124869 [09:56<7:10:08,  4.26it/s, loss=2.57] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20:  24%|‚ñà‚ñà‚ñç       | 30005/124869 [19:23<3:34:45,  7.36it/s, loss=2.56] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20:  36%|‚ñà‚ñà‚ñà‚ñå      | 45003/124869 [29:40<7:01:08,  3.16it/s, loss=2.54] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 59998/124869 [40:42<5:43:52,  3.14it/s, loss=2.52] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 75003/124869 [51:12<4:28:51,  3.09it/s, loss=2.52] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 90003/124869 [1:01:09<2:27:07,  3.95it/s, loss=2.52]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105006/124869 [1:10:26<1:35:06,  3.48it/s, loss=2.51]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 120003/124869 [1:19:45<14:23,  5.64it/s, loss=2.51]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 124870it [1:23:02, 25.06it/s, loss=2.51]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch19.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20:  12%|‚ñà‚ñè        | 15004/124869 [09:43<2:40:29, 11.41it/s, loss=2.5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20:  24%|‚ñà‚ñà‚ñç       | 30003/124869 [19:21<3:12:29,  8.21it/s, loss=2.5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20:  36%|‚ñà‚ñà‚ñà‚ñå      | 45003/124869 [29:19<2:49:53,  7.83it/s, loss=2.48] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 60005/124869 [39:33<4:41:55,  3.83it/s, loss=2.47] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 75005/124869 [49:23<1:58:15,  7.03it/s, loss=2.46] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 90000/124869 [59:25<3:18:18,  2.93it/s, loss=2.46] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 105006/124869 [1:09:28<1:23:57,  3.94it/s, loss=2.46]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 119998/124869 [1:19:31<02:34, 31.48it/s, loss=2.46]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 124870it [1:22:41, 25.17it/s, loss=2.46]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint: checkpoints\\epoch20.pth\n"
     ]
    }
   ],
   "source": [
    "start_epoch, start_batch_in_epoch, prev_loss = 0, 0, None\n",
    "checkpoint_files = sorted(glob.glob(os.path.join(CHECKPOINT_PATH, \"epoch*.pth\")))\n",
    "if checkpoint_files:\n",
    "    last_checkpoint = checkpoint_files[-1]\n",
    "    start_epoch, start_batch_in_epoch, prev_loss = load_checkpoint(model, optimizer, last_checkpoint, device)\n",
    "    print(f\"Resuming from {last_checkpoint}, epoch={start_epoch}, batch_in_epoch={start_batch_in_epoch}, prev_loss={prev_loss:.4f}\")\n",
    "    \n",
    "\n",
    "# TODO\n",
    "# Add weight decay\n",
    "# Switch to sparse adam\n",
    "# Maybe add hybrid linear/non-linear layer\n",
    "# checkpoint losses + remove io\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, total=TOTAL_BATCHES, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        if epoch == start_epoch and i < start_batch_in_epoch:\n",
    "            continue\n",
    "        \n",
    "        user_idx_batch, anime_idx_batch, score_batch = batch\n",
    "        user_idx_batch = user_idx_batch.to(device)\n",
    "        anime_idx_batch = anime_idx_batch.to(device)\n",
    "        score_batch = score_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(user_idx_batch, anime_idx_batch, anime_genres.to(device))\n",
    "        loss = loss_fn(pred, score_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(user_idx_batch)\n",
    "        count += len(user_idx_batch)\n",
    "        \n",
    "        avg_loss = total_loss / count\n",
    "        progress_bar.set_postfix(loss=avg_loss)\n",
    "\n",
    "        # periodic checkpoint\n",
    "        if (i + 1) % CHECKPOINT_INTERVAL == 0:\n",
    "            ckpt_path = os.path.join(CHECKPOINT_PATH, f\"epoch{epoch+1:02d}.pth\")\n",
    "            save_checkpoint(model, optimizer, epoch, i + 1, avg_loss, ckpt_path)\n",
    "            progress_bar.write(f\"üíæ Saved checkpoint: {ckpt_path}\")\n",
    "\n",
    "    # end of epoch checkpoint\n",
    "    ckpt_path = os.path.join(CHECKPOINT_PATH, f\"epoch{epoch+1:02d}.pth\")\n",
    "    save_checkpoint(model, optimizer, epoch + 1, 0, total_loss / count, ckpt_path)\n",
    "    progress_bar.write(f\"üíæ Saved checkpoint: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa0acf1",
   "metadata": {},
   "source": [
    "## 8. Make Recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b9c2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making prediction from checkpoints/linear\\epoch20.pth, loss=2.4619\n",
      "Recommendations for catfire8\n",
      "                                                  title  \\\n",
      "6411  Chounai Shinsengumi wo Tasuke-gumi Mezashi-tai...   \n",
      "532                        Seiken Gakuin no Makentsukai   \n",
      "191   Tensei Kenja no Isekai Life: Dai-2 no Shokugyo...   \n",
      "497                   Benriya Saitou-san, Isekai ni Iku   \n",
      "9642                                           Guo Qiao   \n",
      "258                          IDOLiSH7 3rd Season Part 2   \n",
      "656                                  Kocchi Muite Miiko   \n",
      "6579                    Kaitou Queen wa Circus ga Osuki   \n",
      "9774                                Xiao Xiao Ji Qi Ren   \n",
      "192   Shijou Saikyou no Daimaou, Murabito A ni Tense...   \n",
      "\n",
      "                                              anime_url  \n",
      "6411  https://myanimelist.net/anime/35152/Chounai_Sh...  \n",
      "532   https://myanimelist.net/anime/50184/Seiken_Gak...  \n",
      "191   https://myanimelist.net/anime/47163/Tensei_Ken...  \n",
      "497   https://myanimelist.net/anime/50854/Benriya_Sa...  \n",
      "9642       https://myanimelist.net/anime/43543/Guo_Qiao  \n",
      "258   https://myanimelist.net/anime/46654/IDOLiSH7_3...  \n",
      "656   https://myanimelist.net/anime/42083/Kocchi_Mui...  \n",
      "6579  https://myanimelist.net/anime/49423/Kaitou_Que...  \n",
      "9774  https://myanimelist.net/anime/43498/Xiao_Xiao_...  \n",
      "192   https://myanimelist.net/anime/48415/Shijou_Sai...  \n"
     ]
    }
   ],
   "source": [
    "checkpoint_files = sorted(glob.glob(os.path.join(CHECKPOINT_PATH, \"epoch*.pth\")))\n",
    "if checkpoint_files:\n",
    "    last_checkpoint = checkpoint_files[-1]\n",
    "    _, _, loss = load_checkpoint(model, optimizer, last_checkpoint, device)\n",
    "    print(f\"Making prediction from {last_checkpoint}, loss={loss:.4f}\")\n",
    "\n",
    "USERNAME = 'sirawesomeness'\n",
    "# USERNAME = 'catfire8'\n",
    "\n",
    "user_idx = user_id_to_idx[USERNAME]\n",
    "top_indices, top_scores = model.recommend(user_idx, anime_genres, device=device)\n",
    "df = pd.read_csv('data/original/anime.csv',sep='\\t')\n",
    "df = df.iloc[top_indices]\n",
    "print(f\"Recommendations for {USERNAME}\")\n",
    "print(df[['title','anime_url']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
